{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL BUILDING\n",
    "\n",
    "* The features that we've analyzed to matter include\n",
    "    * net_ope_exp\n",
    "    * winner\n",
    "    * votes\n",
    "    * can_par_aff\n",
    "    * can_off\n",
    "    * can_off_dis\n",
    "    * can_off_sta\n",
    "    * can_inc_cha_ope_sea\n",
    "    * campaign_duration\n",
    "    \n",
    "* create two dataframes for classification and regression tasks\n",
    "    * create two subframes from the original frames for granularity of prediction\n",
    "        * Regression_data\n",
    "            * H_model_data_reg\n",
    "            * P_model_data_reg\n",
    "            * S_model_data_reg\n",
    "        * Classification_data\n",
    "            * H_model_data_cla\n",
    "            * P_model_data_cla\n",
    "            * S_model_data_cla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "\n",
    "data = pd.read_csv(\"../data_secgrp/model_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['can_id', 'can_nam', 'can_off', 'can_off_sta', 'can_off_dis',\n",
       "       'can_par_aff', 'can_inc_cha_ope_sea', 'can_str1', 'can_cit', 'can_sta',\n",
       "       'can_zip', 'ind_ite_con', 'ind_uni_con', 'ind_con', 'par_com_con',\n",
       "       'oth_com_con', 'can_con', 'tot_con', 'tra_fro_oth_aut_com', 'can_loa',\n",
       "       'tot_loa', 'off_to_ope_exp', 'oth_rec', 'tot_rec', 'ope_exp',\n",
       "       'can_loa_rep', 'tot_loa_rep', 'ind_ref', 'oth_com_ref', 'tot_con_ref',\n",
       "       'oth_dis', 'tot_dis', 'cas_on_han_beg_of_per', 'cas_on_han_clo_of_per',\n",
       "       'net_con', 'net_ope_exp', 'deb_owe_by_com', 'cov_sta_dat',\n",
       "       'cov_end_dat', 'winner', 'votes', 'campaign_duration'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create regression data\n",
    "Regression_data = data[['can_off', 'can_off_sta', 'can_off_dis', 'can_inc_cha_ope_sea', 'net_ope_exp', 'can_par_aff','campaign_duration','votes']]\n",
    "\n",
    "\n",
    "#create classification data\n",
    "Classification_data = data[['can_off', 'can_off_sta', 'can_off_dis', 'can_inc_cha_ope_sea', 'net_ope_exp', 'can_par_aff','campaign_duration','winner']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check regression analysis possibility**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "can_off                0.000000\n",
       "can_off_sta            0.000000\n",
       "can_off_dis            0.001103\n",
       "can_inc_cha_ope_sea    0.001103\n",
       "net_ope_exp            0.082139\n",
       "can_par_aff            0.000551\n",
       "campaign_duration      0.000000\n",
       "votes                  0.791069\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Regression_data.isna().sum()/len(Regression_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "* approximately 80% of the votes data is missing, this will make regression analysis inaccurate, therefore, we will not look into extracting data for regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceed to check classification possibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "can_off                  0\n",
       "can_off_sta              0\n",
       "can_off_dis              2\n",
       "can_inc_cha_ope_sea      2\n",
       "net_ope_exp            149\n",
       "can_par_aff              1\n",
       "campaign_duration        0\n",
       "winner                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classification_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handle missing data in classification data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "Classification_data['can_off_dis'] = imp_mode.fit_transform(Classification_data[['can_off_dis']]).copy()\n",
    "Classification_data['can_inc_cha_ope_sea'] = imp_mode.fit_transform(Classification_data[['can_inc_cha_ope_sea']]).copy()\n",
    "Classification_data['net_ope_exp'] = Classification_data['net_ope_exp'].fillna(-99999999999999999999999).copy()\n",
    "Classification_data['can_par_aff'] = imp_mode.fit_transform(Classification_data[['can_par_aff']]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "can_off                0\n",
       "can_off_sta            0\n",
       "can_off_dis            0\n",
       "can_inc_cha_ope_sea    0\n",
       "net_ope_exp            0\n",
       "can_par_aff            0\n",
       "campaign_duration      0\n",
       "winner                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classification_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove a single uninformative data point that affects the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classification_data = Classification_data[Classification_data.can_par_aff != 'PPT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make respective dataframes\n",
    "H_model_data_cla = Classification_data.loc[Classification_data['can_off'] == 'H']\n",
    "P_model_data_cla = Classification_data.loc[Classification_data['can_off'] == 'P']\n",
    "S_model_data_cla = Classification_data.loc[Classification_data['can_off'] == 'S']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build classification pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test pipeline on house of rep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = H_model_data_cla.iloc[:,:-1]\n",
    "y = H_model_data_cla.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine categorical and numerical features\n",
    "\n",
    "numerical_ix = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_ix = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "\n",
    "# define the data preparation for the columns\n",
    "t = [('cat', OneHotEncoder(), categorical_ix), ('num', MinMaxScaler(), numerical_ix)]\n",
    "col_transform = ColumnTransformer(transformers=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base the model\n",
    "\n",
    "model = SVC(kernel='rbf',gamma='scale',C=100)\n",
    "# define the data preparation and modeling pipeline\n",
    "pipeline = Pipeline(steps=[('prep',col_transform), ('m', model) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and predict pipeline on house of rep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide data into train and test split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('cat', OneHotEncoder(),\n",
       "                                                  Index(['can_off', 'can_off_sta', 'can_inc_cha_ope_sea', 'can_par_aff'], dtype='object')),\n",
       "                                                 ('num', MinMaxScaler(),\n",
       "                                                  Index(['can_off_dis', 'net_ope_exp', 'campaign_duration'], dtype='object'))])),\n",
       "                ('m', SVC(C=100))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluating base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix is: \n",
      "[[192   7]\n",
      " [ 20  67]]\n",
      "accuracy of the base model on house of rep election is: 90.55944055944056%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "print(f'confusion matrix is: \\n{confusion_matrix(y_true=y_val, y_pred=y_pred)}')\n",
    "print(f'accuracy of the base model on house of rep election is: {accuracy_score(y_val, y_pred) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create function to evaluate different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_(models_dict, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    a function that takes in a dictionary of models along with train and test data\n",
    "    to calculate the f1_score and accuracy score of the built pipeline then return a dataframe as the output\n",
    "    \n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    for i in models_dict:\n",
    "        model_name = str(i)\n",
    "        model = models_dict[i]\n",
    "        \n",
    "        pipeline = Pipeline(steps=[('prep',col_transform), ('m', model) ])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        test_pred = pipeline.predict(X_val)\n",
    "        metric_1 = accuracy_score(y_val, test_pred) * 100\n",
    "        metric_2 = f1_score(y_val, test_pred, average='weighted')\n",
    "        metrics[i] = metric_1, metric_2\n",
    "        \n",
    "    metrics_df = pd.DataFrame.from_dict(metrics, orient='index', columns=['Accuracy score', 'f1_score'])\n",
    "    return metrics_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>91.258741</td>\n",
       "      <td>0.910052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_reg</th>\n",
       "      <td>91.258741</td>\n",
       "      <td>0.910052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>91.258741</td>\n",
       "      <td>0.910052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>90.909091</td>\n",
       "      <td>0.906245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy score  f1_score\n",
       "xgboost             91.258741  0.910052\n",
       "log_reg             91.258741  0.910052\n",
       "svm                 91.258741  0.910052\n",
       "random forest       90.909091  0.906245"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dictionary of classification models\n",
    "candidate_models = {'xgboost':XGBClassifier(), 'log_reg': LogisticRegression(), 'svm':SVC(), 'random forest': RandomForestClassifier() }\n",
    "\n",
    "#cal test_model_function\n",
    "test_model_(candidate_models, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
